{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilingual-e5-large võrdlus eri dokumendiparsimisemeetodite põhjal\n",
    "1) Esimene samm (meile) - võrrelda semantilist otsingut kaht viisi parsitud andmetel. Siin tuleks välja mõelda, kuidas otsing kõige paremini üles ehitada. Tekst peaks sisaldama vähemalt ühte sõna terminist?\n",
    "2) Teine samm (terminoloogidele) - tekstiotsingu ja semantilise otsingu vahe\n",
    "3) Võib võrrelda, kas API-päringu vastusega sidumine võib semantilisel otsingul anda paremaid tulemusi.\n",
    "\n",
    "\n",
    "#### Terminoloogide valitud terminid:\n",
    "* *area reconnaissance* – meil arutatud ja Militermis olemas, peaks leidma erinevaid definitsioone ja kasutusnäiteid;\n",
    "* *capability* – laialt kasutatud sõna, mis ka militaarvaldkonnas defineeritud; saaks katsetada koos terminitega capability planning, capability development, capability management;\n",
    "* *battle tank* ja/või *main battle tank* – sage kasutus, leitavad natuke erinevad lähenemised, TI harjutamiseks tundub hea, sest infot jagub;\n",
    "* *operational environment*\n",
    "* *area of operations* \n",
    "* *air operation* – väga nö lihtne ja tavaline termin, kas TI leiab meie konteksti vajalikku infot;\n",
    "* *air defence* - lihtne termin peidab keerukamat sisu ja TI peaks leidma mitu paralleelset kontseptsiooni;\n",
    "* *rotary-wing aircraft* – terminal hulk sünonüüme ja (heli)kopteritest peaks leidma päris palju infot eri kohtadest;\n",
    "* *urban warfare* – väga palju sünonüüme, lai kasutus;\n",
    "* *forward defence*, *forward defence posture* – ise veel juurdleme ja otsime infot, aga vaataks TI võimeid;\n",
    "* *psychological operation*, *psychological warfare* – kui mingil hetkel tahaks katsetada või õpetada, kuidas TI tunneb ära sama konteksti või termini eri versioonid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impordid\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import (FieldCondition, Filter, MatchText,\n",
    "                                       MatchValue)\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_host = 'ekivm'\n",
    "client_port = 6333\n",
    "\n",
    "# SentenceTransformers model\n",
    "embedding_model = 'intfloat/multilingual-e5-large'\n",
    "\n",
    "collection_test = 'kva_test_collection'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baasiühendus\n",
    "client = QdrantClient(client_host, port=client_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mudeli initsialiseerimine\n",
    "model = SentenceTransformer(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Semantilise otsingu meetod\n",
    "query_filter_validated = Filter(\n",
    "            must=[\n",
    "            FieldCondition(\n",
    "                key=\"validated\",\n",
    "                match=MatchValue(\n",
    "                    value=True,\n",
    "                ),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "#query_filter_keyword = Filter()\n",
    "# todo: implement keyword search\n",
    "\n",
    "\n",
    "def get_similarities(text, query_filter, collection_name=\"kva_test_collection\", response_limit = 5):\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=list(model.encode(text, normalize_embeddings=True).astype(float)),\n",
    "        query_filter=query_filter,\n",
    "        limit=response_limit,\n",
    "        timeout=100)\n",
    "    \n",
    "    result_dict = defaultdict(list)\n",
    "    \n",
    "    for point in search_result:\n",
    "        if not point.payload:\n",
    "            continue\n",
    "        result_dict['response_text'].append(point.payload[\"text\"])\n",
    "        result_dict['response_type'].append(point.payload[\"content_type\"])\n",
    "        result_dict['score'].append(point.score)\n",
    "        result_dict['filename'].append(point.payload[\"filename\"])\n",
    "        result_dict['page_no'].append(point.payload[\"page_number\"])\n",
    "\n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties = {\n",
    "    'white-space': 'pre-wrap', # Allows text to wrap within cells\n",
    "    'width': '300px', # Adjust as needed\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Esialgne tulemuste võrdluse tabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_structured = 'kva_documents_structured'\n",
    "collection_simple = 'kva_documents_simple'\n",
    "\n",
    "collections_to_use = [collection_test] # [collection_simple, collection_structured]\n",
    "\n",
    "query_inputs = [\n",
    "    'area reconnaissance',\n",
    "    'capability',\n",
    "    'capability planning',\n",
    "    'capability development',\n",
    "    'capability management',\n",
    "    'battle tank',\n",
    "    'main battle tank',\n",
    "    'operational environment',\n",
    "    'area of operations',\n",
    "    'air operation',\n",
    "    'air defence',\n",
    "    'rotary-wing aircraft',\n",
    "    'urban warfare',\n",
    "    'forward defence',\n",
    "    'forward defence posture',\n",
    "    'psychological operation',\n",
    "    'psychological warfare'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_col_data = list()\n",
    "similarity_ranks_col_data = list()\n",
    "results_by_collection = {coll: [] for coll in collections_to_use}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {coll: [] for coll in collections_to_use}\n",
    "data.update({'märksõna': [], 'sarnasus': []})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in query_inputs:\n",
    "\n",
    "    query_responses = defaultdict(list)\n",
    "    \n",
    "    for collection in collections_to_use:\n",
    "\n",
    "        responses = get_similarities('query : ' + query, query_filter_validated, collection, response_limit=5)\n",
    "        \n",
    "        for text, type, score, fname, page in zip(responses['response_text'], responses['response_type'], responses['score'], responses['filename'], responses['page_no']):\n",
    "            response_text = f'Fail: {fname}\\nLk: {page}\\nTüüp: {type}\\nOtsingutulemus: {text}'\n",
    "            query_responses[collection].append(response_text)\n",
    "\n",
    "    no_of_responses = len(query_responses[collection])\n",
    "\n",
    "    data['sarnasus'].extend(list(range(1, no_of_responses + 1)))\n",
    "    data['märksõna'].extend([query]*no_of_responses)\n",
    "    \n",
    "    for k, v in query_responses.items():\n",
    "        data[k].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(query_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in data.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "df.set_index(['märksõna', 'sarnasus'], inplace=True)\n",
    "\n",
    "display(df.style.set_properties(**df_properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Märksõna\": keywords_col_data,\n",
    "    \"Parser\": collections_col_data,\n",
    "    \"Sarnasus\": similarity_ranks_col_data,\n",
    "    \"Vaste\": results_col_data\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.set_index(['Märksõna', 'Sarnasus'], inplace=True)\n",
    "display(df.style.set_properties(**df_properties))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a MultiIndex for columns\n",
    "columns = pd.MultiIndex.from_tuples([\n",
    "    ('A', 'foo'), ('A', 'bar'),\n",
    "    ('B', 'foo'), ('B', 'bar')\n",
    "], names=['level_1', 'level_2'])\n",
    "\n",
    "\n",
    "# Creating a DataFrame with the MultiIndex for columns\n",
    "df = pd.DataFrame(np.random.randn(3, 4), columns=['level_1', 'level_2', 'foo', 'bar'])\n",
    "#df.set_index(['foo', 'bar'], inplace=True)\n",
    "\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Step 1: Reset the index\n",
    "df_reset = df.reset_index()\n",
    "\n",
    "# Step 2: Pivot the DataFrame\n",
    "df_pivoted = df_reset.pivot(index=['Märksõna', 'Sarnasus'], columns='Parser', values='Vaste')\n",
    "\n",
    "# Step 3: Reset the index (optional)\n",
    "df_final = df_pivoted.reset_index()\n",
    "\n",
    "# Display the final DataFrame\n",
    "display(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw = 'explain the meaning of \"battle tank\" in context of given file'\n",
    "query = 'query: ' + kw\n",
    "\n",
    "response_df = get_similarities(kw, collection_name=collection_test, query_filter=query_filter_validated).style.set_properties(**df_properties)\n",
    "\n",
    "display(response_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
