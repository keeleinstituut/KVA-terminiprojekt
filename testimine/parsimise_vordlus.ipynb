{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilingual-e5-large võrdlus eri dokumendiparsimisemeetodite põhjal\n",
    "1) Esimene samm (meile) - võrrelda semantilist otsingut kaht viisi parsitud andmetel. Siin tuleks välja mõelda, kuidas otsing kõige paremini üles ehitada. Tekst peaks sisaldama vähemalt ühte sõna terminist?\n",
    "2) Teine samm (terminoloogidele) - tekstiotsingu ja semantilise otsingu vahe\n",
    "3) Võib võrrelda, kas API-päringu vastusega sidumine võib semantilisel otsingul anda paremaid tulemusi.\n",
    "\n",
    "\n",
    "#### Terminoloogide valitud terminid:\n",
    "* *area reconnaissance* – meil arutatud ja Militermis olemas, peaks leidma erinevaid definitsioone ja kasutusnäiteid;\n",
    "* *capability* – laialt kasutatud sõna, mis ka militaarvaldkonnas defineeritud; saaks katsetada koos terminitega capability planning, capability development, capability management;\n",
    "* *battle tank* ja/või *main battle tank* – sage kasutus, leitavad natuke erinevad lähenemised, TI harjutamiseks tundub hea, sest infot jagub;\n",
    "* *operational environment*\n",
    "* *area of operations* \n",
    "* *air operation* – väga nö lihtne ja tavaline termin, kas TI leiab meie konteksti vajalikku infot;\n",
    "* *air defence* - lihtne termin peidab keerukamat sisu ja TI peaks leidma mitu paralleelset kontseptsiooni;\n",
    "* *rotary-wing aircraft* – terminal hulk sünonüüme ja (heli)kopteritest peaks leidma päris palju infot eri kohtadest;\n",
    "* *urban warfare* – väga palju sünonüüme, lai kasutus;\n",
    "* *forward defence*, *forward defence posture* – ise veel juurdleme ja otsime infot, aga vaataks TI võimeid;\n",
    "* *psychological operation*, *psychological warfare* – kui mingil hetkel tahaks katsetada või õpetada, kuidas TI tunneb ära sama konteksti või termini eri versioonid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impordid\n",
    "from collections import defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import (FieldCondition, Filter, MatchText,\n",
    "                                       MatchValue)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_host = 'localhost'\n",
    "client_port = 6333\n",
    "\n",
    "# SentenceTransformers model\n",
    "embedding_model = 'intfloat/multilingual-e5-large'\n",
    "\n",
    "collection_test = 'kva_test_collection'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baasiühendus\n",
    "client = QdrantClient(client_host, port=client_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mudeli initsialiseerimine\n",
    "model = SentenceTransformer(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_properties = {\n",
    "    'white-space': 'pre-wrap', # Allows text to wrap within cells\n",
    "    'width': '300px', # Adjust as needed\n",
    "    'text-align': 'left'\n",
    "}\n",
    "\n",
    "# Semantilise otsingu meetod\n",
    "query_filter_validated = Filter(\n",
    "            must=[\n",
    "            FieldCondition(\n",
    "                key=\"validated\",\n",
    "                match=MatchValue(\n",
    "                    value=True,\n",
    "                ),\n",
    "            )\n",
    "        ])\n",
    "\n",
    "#query_filter_keyword = Filter()\n",
    "# todo: implement keyword search\n",
    "\n",
    "def calculate_ranking_similarity(collections: list, result_df, query: str):\n",
    "    \"\"\"\n",
    "    Calculates the similarity percentage between two collections based on the correct sequence of responses.\n",
    "\n",
    "    Args:\n",
    "    - collections (list): A list containing two collections to compare.\n",
    "    - result_df (DataFrame): A DataFrame containing the search results for the given query.\n",
    "    - query (str): The query string used to search the collections.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: A tuple containing the query string and the calculated similarity percentage.\n",
    "    \"\"\"\n",
    "\n",
    "    collections_to_compare = collections # two collections\n",
    "\n",
    "    file_pattern = re.compile('^Fail: ([^\\n]*)\\n')\n",
    "    page_pattern = re.compile('\\nLk: ([^\\n]*)\\n')\n",
    "\n",
    "\n",
    "    df = result_df.loc[query]\n",
    "\n",
    "    # Extracting files and page numbers for each response in each collection\n",
    "    result_files_by_collection = {collection: [] for collection in collections_to_compare}\n",
    "    for row in df.itertuples():\n",
    "        for collection in collections_to_compare:\n",
    "            response = getattr(row, collection)\n",
    "            filename = re.search(file_pattern, response).group(1)\n",
    "            page_no = re.search(page_pattern, response).group(1)\n",
    "            result_files_by_collection[collection].append((filename, page_no))\n",
    "    \n",
    "    # Calculating similarity % based on correct sequence of responses\n",
    "    response_count = 0\n",
    "    similar_response_count = 0\n",
    "    for c1, c2 in zip(*[v for v in result_files_by_collection.values()]):\n",
    "        if c1 == c2:\n",
    "            similar_response_count += 1\n",
    "        response_count += 1\n",
    "\n",
    "    similarity = similar_response_count*100/response_count\n",
    "    \n",
    "    return(query, similarity)\n",
    "\n",
    "\n",
    "def get_similarities(text, query_filter, collection_name=\"kva_test_collection\", response_limit = 5):\n",
    "    \"\"\"\n",
    "    Searches for similar documents in a collection based on a given text and query filter.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The text to search for similar documents.\n",
    "    - query_filter (dict): A dictionary specifying the filter criteria for the search.\n",
    "    - collection_name (str, optional): The name of the collection to search within, defaults to \"kva_test_collection\".\n",
    "    - response_limit (int, optional): The maximum number of search results to return, defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing lists of response texts, response types, scores, filenames, and page numbers.\n",
    "    \"\"\"\n",
    "\n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=list(model.encode(text, normalize_embeddings=True).astype(float)),\n",
    "        query_filter=query_filter,\n",
    "        limit=response_limit)\n",
    "    \n",
    "    result_dict = defaultdict(list)\n",
    "    \n",
    "    for point in search_result:\n",
    "        if not point.payload:\n",
    "            continue\n",
    "        result_dict['response_text'].append(point.payload[\"text\"])\n",
    "        result_dict['response_type'].append(point.payload[\"content_type\"])\n",
    "        result_dict['score'].append(point.score)\n",
    "        result_dict['filename'].append(point.payload[\"filename\"])\n",
    "        result_dict['page_no'].append(point.payload[\"page_number\"])\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "\n",
    "def get_group_similarities(text, query_filter, collection_name=\"kva_test_collection\", response_limit = 5, group_size=4):\n",
    "    \"\"\"\n",
    "    Searches for similar documents in a collection based on a given text and query filter, grouping results.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The text to search for similar documents.\n",
    "    - query_filter (dict): A dictionary specifying the filter criteria for the search.\n",
    "    - collection_name (str, optional): The name of the collection to search within, defaults to \"kva_test_collection\".\n",
    "    - response_limit (int, optional): The maximum number of search results to return, defaults to 5.\n",
    "    - group_size (int, optional): The maximum number of results per group, defines the number of filenames and page numbers returned per group.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing lists of response texts, response types, scores, filenames, and page numbers for each group.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    search_params = {\n",
    "    \"query_vector\": list(model.encode(text, normalize_embeddings=True).astype(float)),\n",
    "    \"limit\": 5, \n",
    "    \"group_by\": \"text\", \n",
    "    \"group_size\": group_size,\n",
    "    \"with_payload\": True,\n",
    "    \"with_vectors\": False,\n",
    "    \"query_filter\": query_filter\n",
    "    }\n",
    "\n",
    "    # Perform the search\n",
    "    search_results = client.search_groups(collection_name=collection_name, **search_params).groups\n",
    "\n",
    "    result_dict = defaultdict(list)\n",
    "\n",
    "    for group in search_results:\n",
    "\n",
    "        points = group.hits\n",
    "\n",
    "        result_dict['response_text'].append(group.id)\n",
    "        result_dict['response_type'].append(points[0].payload[\"content_type\"])\n",
    "        result_dict['score'].append(points[0].score)\n",
    "        result_dict['filename'].append([point.payload[\"filename\"] for point in points])\n",
    "        result_dict['page_no'].append([point.payload[\"page_number\"] for point in points])\n",
    "    \n",
    "    return result_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testandmestiku koostamine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testandmestiku alusandmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_structured = 'kva_documents_structured'\n",
    "collection_simple = 'kva_documents_simple'\n",
    "\n",
    "collections_to_use = [collection_simple, collection_structured] \n",
    "\n",
    "query_inputs = [\n",
    "    'battle tank - self-propelled armoured fighting vehicle, capable of heavy firepower, primarily of a high muzzle velocity direct fire main gun necessary to engage armoured and other targets, with high cross-country mobility, with a high level of self-protection, and which is not designed and equipped primarily to transport combat troops',\n",
    "    'area of operations - area within a joint operations area defined by the joint force commander for conducting tactical level operations',\n",
    "    'urban warfare - combats de rues en ville',\n",
    "    \"forward defence - strategie visant a arreter un agresseur aussi pres que possible des frontieres;s'oppose a la defense en profondeur(1)\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esimene testandmestik (duplikaatidega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {coll: [] for coll in collections_to_use}\n",
    "data.update({'märksõna': [], 'sarnasus': []})\n",
    "\n",
    "for query in query_inputs:\n",
    "\n",
    "    query_responses = defaultdict(list)\n",
    "    \n",
    "    for collection in collections_to_use:\n",
    "\n",
    "        responses = get_similarities('query : ' + query, query_filter_validated, collection, response_limit=5)\n",
    "        \n",
    "        for text, type, score, fname, page in zip(responses['response_text'], responses['response_type'], responses['score'], responses['filename'], responses['page_no']):\n",
    "            response_text = f'Fail: {fname}\\nLk: {page}\\nTüüp: {type}\\n\\n{text}'\n",
    "            query_responses[collection].append(response_text)\n",
    "\n",
    "    no_of_responses = len(query_responses[collection])\n",
    "\n",
    "    data['sarnasus'].extend(list(range(1, no_of_responses + 1)))\n",
    "    data['märksõna'].extend([query]*no_of_responses)\n",
    "    \n",
    "    for k, v in query_responses.items():\n",
    "        data[k].extend(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exceli tabelina salvestamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "df.set_index(['märksõna', 'sarnasus'], inplace=True)\n",
    "\n",
    "df[:].to_excel('~/projects/kva/kva_data/test_data/test_2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hindamine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in query_inputs:\n",
    "    print(calculate_ranking_similarity(collections_to_use, df, query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teine testandmestik (grupeeritud vastused, duplikaatideta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {coll: [] for coll in collections_to_use}\n",
    "data.update({'märksõna': [], 'sarnasus': []})\n",
    "\n",
    "for query in query_inputs:\n",
    "\n",
    "    query_responses = defaultdict(list)\n",
    "    \n",
    "    for collection in collections_to_use:\n",
    "\n",
    "        responses = get_group_similarities('query : ' + query, query_filter_validated, collection, response_limit=5)\n",
    "        \n",
    "        for text, type, score, fname, page in zip(responses['response_text'], responses['response_type'], responses['score'], responses['filename'], responses['page_no']):\n",
    "            response_text = f'Fail: {fname}\\nLk: {page}\\nTüüp: {type}\\n\\n{text}'\n",
    "            query_responses[collection].append(response_text)\n",
    "\n",
    "    no_of_responses = len(query_responses[collection])\n",
    "\n",
    "    data['sarnasus'].extend(list(range(1, no_of_responses + 1)))\n",
    "    data['märksõna'].extend([query]*no_of_responses)\n",
    "    \n",
    "    for k, v in query_responses.items():\n",
    "        data[k].extend(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exceli tabelina salvestamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "df.set_index(['märksõna', 'sarnasus'], inplace=True)\n",
    "df[:].to_excel('~/projects/kva/kva_data/test_data/test_2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hindamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in query_inputs:\n",
    "    print(calculate_ranking_similarity(collections_to_use, df, query))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
