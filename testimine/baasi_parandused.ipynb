{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Liiga lühikeste kirjete eemaldamine baasist \n",
    "\n",
    "Muudab *collection*'is validated=False kõigi kirjete puhul, mille tekst on lühem kui kaks sõna. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "from datetime import datetime, timedelta\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_host = 'localhost'\n",
    "client_port = 6333\n",
    "\n",
    "collection_name = 'test123'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = QdrantClient(client_host, port=client_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.get_collection(collection_name).vectors_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll(collection_name, limit=10000, offset=0):\n",
    "    points, next_page_offset = client.scroll(\n",
    "        collection_name=collection_name,\n",
    "        limit=limit,\n",
    "        offset=offset)\n",
    "    return points, next_page_offset\n",
    "\n",
    "def get_invalid_point_ids(points):\n",
    "    \"\"\"Get id-s of entries with less than two words from a given set of Point objects.\"\"\"\n",
    "    invalid_point_ids = []\n",
    "    for point in points:\n",
    "        point_id = point.id\n",
    "        text = point.payload['text']\n",
    "\n",
    "        if text.strip().count(' ') == 0 and text.strip().count('\\n') == 0:\n",
    "            invalid_point_ids.append(point_id)\n",
    "    return invalid_point_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alla kahe sõnaliste kannete uuendamine baasis -- valid==False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10000\n",
    "offset=0\n",
    "points = ['*']*limit\n",
    "\n",
    "# Iterate over the whole collection.\n",
    "while offset is not None:\n",
    "    points, offset = scroll(collection_name, limit=limit, offset=offset)\n",
    "    invalid_point_ids = get_invalid_point_ids(points)\n",
    "\n",
    "    # Get invalid points\n",
    "    invalid_points, _ = client.scroll(\n",
    "    collection_name=collection_name,\n",
    "    scroll_filter=models.Filter(\n",
    "        must=[\n",
    "            models.HasIdCondition(has_id=invalid_point_ids),\n",
    "        ],\n",
    "    ),\n",
    "    limit=limit\n",
    "    )\n",
    "\n",
    "    # Update invalid points with valid = False in the collection\n",
    "\n",
    "    for point in invalid_points:\n",
    "\n",
    "        payload = point.payload\n",
    "        payload['validated'] = False\n",
    "\n",
    "        client.set_payload(\n",
    "          collection_name=collection_name,\n",
    "          payload=payload,\n",
    "          points=[point.id])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kuupäevade lisamine baasi - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 1000\n",
    "offset=0\n",
    "points = ['*']*limit\n",
    "\n",
    "# Iterate over the whole collection.\n",
    "while offset is not None:\n",
    "    points, offset = scroll(collection_name, limit=limit, offset=offset)\n",
    "\n",
    "    for point in points:\n",
    "        payload = point.payload\n",
    "        payload['date_created'] = (datetime.date(datetime.today()) - timedelta(days=13)).isoformat()\n",
    "        payload['date_modified'] = (datetime.date(datetime.today()) - timedelta(days=13)).isoformat()\n",
    "\n",
    "        client.set_payload(\n",
    "            collection_name=collection_name,\n",
    "            payload=payload,\n",
    "            points=[point.id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def validate_chunk_text(text, min_word_count=10):\n",
    "    text = re.sub('(\\n+| +)', ' ', text).strip()\n",
    "    if len(text.split(' ')) < min_word_count:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10000\n",
    "offset=0\n",
    "points = ['*']*limit\n",
    "\n",
    "# Iterate over the whole collection.\n",
    "while offset is not None:\n",
    "    points, offset = scroll(collection_name, limit=limit, offset=offset)\n",
    "    for point in points:\n",
    "        if not validate_chunk_text(point.payload['text']):\n",
    "            if point.payload[\"validated\"] is True and point.payload[\"content_type\"] != 'term':\n",
    "                print(point.payload['filename'])\n",
    "                print(f'text: {point.payload[\"text\"]}\\ntype:{point.payload[\"content_type\"]}\\nvalid:{point.payload[\"validated\"]}')\n",
    "                print('\\n', '*'*50, '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "private_gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
